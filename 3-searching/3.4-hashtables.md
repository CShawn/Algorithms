# 3.4-散列表(哈希表)HashTables
通过下标访问数组里的元素，该操作的时间复杂度为常数。如果能够将任意类型的键转变为整数，并将该整数作为数组的下标，将值存放在该下标对应的位置，就能像访问数组那样以常数时间复杂度在符号表内查找任意键（及其值）。

散列表：使用散列函数将键转化为数组的索引，来访问数组中的键值对。是算法在时间和空间上作出权衡的经典例子。

## 散列函数
通过数学计算，使得任意类型的数据转换为一个数值，作为数组的索引。由数据经过运算得到的数值为散列值，接下来，可以对数组长度取模即可以得到索引，将数据放入数组。

- 正整数：选择大小为素数(具有较好的均匀性)M的数组，对于任意正整数k，计算k除以M的余数。
- 浮点数：可以用键乘以M，只取结果的整数部分；但可见只用到数字的高位部分，未使用低位部分数据。另一种方法是将32位表示的浮点数当作32位的整数来处理，即用上了数据的全部位数值。
- Double和Long：将前32位和后32位异或（若高32位全是0，异或运算的结果还是数值本身，不会被没有意义的部分影响）。
- 单个字符：可直接使用字符编码表（如ASCII、Unicode）将单个字符转变成整数
- 字符串：由进制转变的计算过程获取思路，将一个字符串看作一个N位的数字，每位上的数是每个字符对应的数值，把这个N位数当作M(一般取质数)进制的数字，当M足够小（最终计算结果不超过int范围），即可通过进制计算得到一个数值，Java中取M为31。计算过程可以根据霍纳法则（秦九韶算法）来简化：如，`ax^3 + bx^2 + cx + d = x(x(ax+b)+c)+d`，也就是提取因子来简化幂运算。
```
int hash = 0;
for (int i = 0; i < s.length(); i++) {
    hash = (R * hash + s.charAt(i)) % M;
}
```
- 组合键：键的类型含有多个整型变量，可以和String类型一样将它们组合起来。例如，键的类型是Date，散列函数为：`int hash = (((day * R + month) % M ) * R + year) % M;`

### equals和hashCode
在java中，如需覆写`equals()`方法，其后需使用哈希值时，必须使用两个`equals()`方法返回`true`的对象，返回相同的`hashCode()`。而反之则不一定。

如果计算散列值比较耗时，那么可以将每个键的散列值缓存起来（在每个键中使用hash字段存储）。

## 散列碰撞
可以看到，散列函数需要具备一致性、高效性、均匀性，而关键是实现散列的均匀性。当有两个或多个数据转换得到相同数值时，就产生了散列碰撞。

出现散列碰撞的处理方法主要有：拉链法、开放地址法、再散列法、建立公共溢出区。

### 链地址法/拉链法[SeparateChaining](SeparateChainingHashST.java)
拉链法指的是散列表的数组下标不直接装填键，每个下标都指向一个集合，将散列值相同的键放在一个集合里面。

```
public class SeparateChainingHashST<Key, Value> {
    private int N; // number of key-value pairs
    private int M; // hash table size
    private SequentialSearchST<Key, Value>[] st; // array of ST objects
    public SeparateChainingHashST() { 
        this(997);
    }
    public SeparateChainingHashST(int M) { 
        // Create M linked lists.
        this.M = M;
        st = (SequentialSearchST<Key, Value>[]) new SequentialSearchST[M];
        for (int i = 0; i < M; i++) {
            st[i] = new SequentialSearchST();
        }
    }
    private int hash(Key key) { 
        return (key.hashCode() & 0x7fffffff) % M;
    }
    public Value get(Key key) { 
        return (Value) st[hash(key)].get(key);
    }
    public void put(Key key, Value val) {
        st[hash(key)].put(key, val);
    }
    public Iterable<Key> keys() {

    }
}
```
Java8之前，采用链表的形式，将出现散列碰撞的多个键，放入一个链表中。查找一个键时，找到`hashCode`对应的索引位置后，在链表中顺序查找。

可见，在最差情况下，散列表会退化成链表，无法实现高效的操作。在Java8之后，加入了红黑树的方式，即每个位置不使用链表而是红黑树的形式，从而实现更高的效率。`HashMap`在[后文](#Java中的HashMap)中详述。

### 开放地址法
开放地址法指的是直接用数组存放元素，当存入某个元素的时候，如果计算出来的数组下标已经装了元素，而且这两个元素确实不相等，那就找别的下标（仍在当前数组中）来存放新的元素。开放地址法作为一个思路，不同的具体方案区别就在于“下个位置怎么找”，有多种探测法。

#### 线性探测法[LinearProbing](LinearProbingHashST.java)
如果键`key`计算出来的初始下标是`H(key)`，当第`i`次发生碰撞时，它的下标是：`h(key) = (H(key) + i) % M，(0<=i<=M-1)`

这里的`M`是数组长度，取余其实是为了防止越界，所以其实这个算式的重点是`H(key) + i`。由于`i`每次都是+1，其实就是从发生碰撞的位置开始向右侧相邻的位置逐一探测。

例如某个键计算出来的数组下标是1，如果位置1已经有元素了，此时是第一次碰撞，`i`取1，就看看位置2是否有元素，如果还有，此时是第二次碰撞，`i`取2，就看位置3是否有元素。

由于开放地址法是直接用数组来存储元素的，所以元素的个数`N`是不能大于数组长度`M`的
- 插入操作：遇到空位说明有地方插入新的键，否则不断探测。
- 查找操作：遇到空位说明本次查找未命中，否则不断探测，直到找到该键或者遇到一个空元素。
- 删除操作：在删除元素后，产生空位，会导致查找产生问题，所以需要对被删除元素右侧相连的所有元素全部重新执行一次插入，并且将原来的数组下标置空。

线性探测法对于相同的键产生的最终位置，往往在一起，称为聚集现象。

```
public class LinearProbingHashST<Key, Value> {
    private int N; // number of key-value pairs in the table
    private int M = 16; // size of linear-probing table
    private Key[] keys; // the keys
    private Value[] vals; // the values
    public LinearProbingHashST() {
        keys = (Key[]) new Object[M];
        vals = (Value[]) new Object[M];
    }
    private int hash(Key key) {
        return (key.hashCode() & 0x7fffffff) % M;
    }
    private void resize(int cap) {
        LinearProbingHashST<Key, Value> t;
        t = new LinearProbingHashST<Key, Value>(cap);
        for (int i = 0; i < M; i++) {
            if (keys[i] != null) {
                t.put(keys[i], vals[i]);
            }
        }
        keys = t.keys;
        vals = t.vals;
        M = t.M;
    }
    public void put(Key key, Value val) {
        if (N >= M/2) resize(2*M); // double M (see text)
        int i;
        for (i = hash(key); keys[i] != null; i = (i + 1) % M)
        if (keys[i].equals(key)) { vals[i] = val; return; }
        keys[i] = key;
        vals[i] = val;
        N++;
    }
    public Value get(Key key) {
        for (int i = hash(key); keys[i] != null; i = (i + 1) % M) {
            if (keys[i].equals(key)) {
                return vals[i];
            }
        }
        return null;
    }
    public void delete(Key key){
        if (!contains(key)) {
            return;
        }
        int i = hash(key);
        while (!key.equals(keys[i])) {
            i = (i + 1) % M;
        }
        keys[i] = null;
        vals[i] = null;
        i = (i + 1) % M;
        while (keys[i] != null) {
            Key keyToRedo = keys[i];
            Value valToRedo = vals[i];
            keys[i] = null;
            vals[i] = null;
            N--;
            put(keyToRedo, valToRedo);
            i = (i + 1) % M;
        }
        N--;
        if (N > 0 N == M/8) resize(M/2);
    }
}
```
#### 二次探测法/平方探测法(Quadratic Probing)
`h(key) = (H(key) ± i^2) % M`，`i`取任何一个值的时候，都有正、负两个情况，这个式子就变成了`H(key)+1`、`H(key)-1`、`H(key)+4`、`H(key)-4`...正号表示向右偏移，负号表示向左偏移（越界后倒着偏移）。例如数组长度为24，对于若干个初始下标为0的“键”，探测的位置分别为1、23、4、20、9、15。

二次探测由于步长大了（而且越来越大），不会像线性探测那么容易出现聚集的情况，但在插入和删除的时候，又有别的问题。

- 插入：例如数组长度为8，我们连续插入初始下标为0的元素，你会得到探测位置序列为：0，1，7，4，4，1，7...陷入循环，导致数组不满。从数学中可知，在`M=4k+3`（k是整数，而且M是质数）的情况下，能够保证，对于长度为M的数组，连续插入M个初始下标相同的元素时，这M个元素刚好装满这个数组，不会出现上述的循环而有空位的情况。

- 删除：二次探测将数组的位置分为三个状态：`empty`、`busy`、`deleted`。在删除元素的时候，不会直接将位置置空，而是标记为`deleted`。此时，插入的时候，如果探测到`empty`，可以直接插入，如果探测到`deleted`，并不能直接插入了，而应继续进行探测，只有遇到`empty`或者遍历完了整个数组，才能确定散列表里没有这个元素，接着才能进行插入。

二次探测法的探测路径是相同的，每次探测都需要进行相同的探测路径才能找到最终位置，称为二次聚集。它的探测位置很有规律，并不够零散。

#### 伪随机探测法
在上述两种探测法的基础上，将步长设为一个随机数，就是伪随机探测法。

#### 双散列法
上述两种探测方法均不够零散，因只有一个变量`i`，双散列法是通过两个不同的散列函数`H(key)`和`H2(key)`来确定探测的位置：`h(key) = (H(key) + i * H2(key))%M`

同样，双散列法亦需要解决二次探测法的数组不满的情况。即当`i`在`[0,M-1]`之间变化时，`h(key)`能取到`[0,M-1]`之间的每一个值。对于一个`key`，`H(key)`和`H2(key)`都是固定的，则可写为：`h(key) = (C1 + i * C2) % M`相当于一元二次方程，`C1`为平移值，可去掉，即：`h(key) = (i * C2) % M`。
> 若`a`和`b`互质，那么对于算式`(a * i) % b`，当`i`=1、2……b-1时，正好可以涵盖0、1……b-1之间的每一个值

由此结论可知，只要`C2`和`M`也就是`H2(key)`和`M`互质即可，一般有两种做法：
- 让`M`为2的幂，让`H2(key)`的值总是奇数，因为奇数和2的幂一定互质。
- 让`M`为质数，让`H2(key)`的值限定在`[1, M-1]`之间，因为质数`M`一定和`[1, M-1]`之间的数互质。

删除操作处理方式与二次探测法相同。

双散列法是开放地址法的几个实现方案里的最优解。

### 再散列法
散列函数输出是同一个位置时，就再使用另一个散列函数进行散列运算，直至不发生冲突。缺点：每次冲突都要重新哈希，计算时间增加。

### 建立公共溢出区
设立另一个表作为溢出表，基本表中存储的是key的记录，一旦发生冲突，不管散列函数得到的值是什么，都填入溢出表。

但这个方法的缺点在于：查找冲突数据的时候，需要遍历溢出表才能得到数据。

### 加载因子
在长度为`M`的数组里面，装有`N`个元素，称`α = N/M`为加载因子或使用率。在拉链法里面，加载因子有可能大于1，在开放地址法里面，加载因子最大只能是1。加载因子越大，碰撞的可能性越大，控制加载因子相当于是在时间和空间的性能之间做出权衡。实际应用一般都在0.5至0.75之间，Java中`HashMap`为0.75。可以通过调整数组大小的方法来保证散列表的使用率不超过`α`。

## Java中的HashMap

- 初始容量为16，加载因子为0.75
- 定义了一个转变成树的最小数组长度位64，如果HashMap里数组的长度小于64，且有链表的长度（在插入新的元素之后）大于8（达到了9），会对散列表进行扩容，重新散列，而不是直接将链表变成红黑树。当数组长度大于64，再次出现链表长度大于8时，则会将链表转为红黑树。因为本身长度小的数组发生散列碰撞的概率就更大，如果过早进行红黑树的转变，就会把散列表搞成一个红黑树的集合，性能接近红黑树，散列的优势被弱化。
- HashMap根据`hash()`获取数组中的索引：`hash()`将`hashCode()`高低16位异或
- 获取索引时，使用位运算代替取模运算，提高效率，因为`n % (2^n) = n & (2^n - 1)`
```
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

index = (n-1) & hash(key);
```